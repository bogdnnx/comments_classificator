# search_logic.py
import asyncio
from typing import List
from utils import vk_request, classify_texts_async, r # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ utils
from database import AsyncSessionLocal # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é –∏–∑ database
from models import SearchQuery, Post, Comment # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ models.py
from datetime import datetime, timedelta
import uuid # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º uuid –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ID


async def process_comments_async(task_id: str, query: str, count: int, cache_key: str):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Å—Ç–æ–≤ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤,
    –∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î.
    """
    try:
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–¥–∞—á–∏ {task_id} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")

        # –û–±–æ–∑–Ω–∞—á–∞–µ–º —Å—Ç–∞—Ä—Ç –∑–∞–¥–∞—á–∏, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –æ—Ç–º–µ—á–µ–Ω–æ
        await r.hset(f"task:{task_id}", mapping={"status": "processing"})

        async with AsyncSessionLocal() as db_session:
            posts_data = await vk_request("newsfeed.search", {"q": query, "count": min(count, 200), "extended": 1})
            if not posts_data:
                print("   ‚ùå –û—Ç–≤–µ—Ç –æ—Ç newsfeed.search –ø—É—Å—Ç–æ–π ‚Äî –ø—Ä–æ–≤–µ—Ä—å URL –∏ —Ç–æ–∫–µ–Ω")
                await r.hset(f"task:{task_id}", mapping={"status": "error", "error": "empty_response"})
                return

            posts = posts_data.get("items", [])
            print(f"   –ù–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç–æ–≤: {len(posts)}")

            from utils import CACHE_TTL # –ò–º–ø–æ—Ä—Ç –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏
            expires_at = datetime.utcnow() + timedelta(seconds=CACHE_TTL)
            search_query = SearchQuery(
                query_text=query,
                count=count,
                task_id=task_id,
                expires_at=expires_at
            )
            db_session.add(search_query)
            await db_session.flush()

            if not posts:
                print("   ‚ùå –ù–µ—Ç –ø–æ—Å—Ç–æ–≤ ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–¥–∞—á—É (–ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)")
                await db_session.commit()
                await r.setex(cache_key, CACHE_TTL, task_id)
                await r.hset(f"task:{task_id}", mapping={"status": "done", "message": "no_posts"})
                return

            all_comments = []
            all_texts = []
            post_cache = {}

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã —Å—Ä–∞–∑—É –¥–∞–∂–µ –µ—Å–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–µ—Ç
            for post in posts:
                owner_id = post["owner_id"]
                post_id = post["id"]
                if (owner_id, post_id) not in post_cache:
                    db_post = Post(
                        vk_post_id=post_id,
                        owner_id=owner_id,
                        text=post.get("text", "")[:5000],
                        date=post.get("date"),
                        url=f"https://vk.com/wall{owner_id}_{post_id}",
                        search_query_id=search_query.id
                    )
                    db_session.add(db_post)
                    await db_session.flush()
                    post_cache[(owner_id, post_id)] = db_post.id

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –ø–æ—Å—Ç—É
                comments_data = await vk_request("wall.getComments", {
                    "owner_id": owner_id,
                    "post_id": post_id,
                    "count": 100
                })
                comments = comments_data.get("items", [])
                for comment in comments:
                    text = comment.get("text", "").strip()
                    if text:
                        all_comments.append({
                            "comment": comment,
                            "owner_id": owner_id,
                            "post_id": post_id
                        })
                        all_texts.append(text)

            if all_texts:
                labels, confidences = await classify_texts_async(all_texts)
                for i, item in enumerate(all_comments):
                    if i >= len(labels):
                        break
                    owner_id = item["owner_id"]
                    post_id = item["post_id"]
                    comment = item["comment"]
                    db_comment = Comment(
                        vk_comment_id=comment["id"],
                        post_id=post_cache[(owner_id, post_id)],
                        from_id=comment.get("from_id"),
                        text=comment["text"][:2000],
                        sentiment=labels[i],
                        sentiment_confidence=float(confidences[i]),
                        date=comment.get("date")
                    )
                    db_session.add(db_comment)

            if all_texts:
                print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {len(all_texts)}")
            else:
                print("   ‚ùå –ù–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

            await db_session.commit()
            await r.setex(cache_key, CACHE_TTL, task_id)
            await r.hset(f"task:{task_id}", mapping={"status": "done"})
            print(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ {task_id}: {e}")
        await r.hset